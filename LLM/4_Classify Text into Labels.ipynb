{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Tagging means labeling a document with classes such as:\n",
        "\n",
        "* Sentiment\n",
        "* Language\n",
        "* Style (formal, informal etc.)\n",
        "* Covered topics\n",
        "* Political tendency"
      ],
      "metadata": {
        "id": "yiPU383sJ_XJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tagging has a few components:**\n",
        "\n",
        "function: Like extraction, tagging uses functions to specify how the model should tag a document\n",
        "schema: defines how we want to tag the document"
      ],
      "metadata": {
        "id": "Jk9mSN52KQt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade --quiet langchain-core"
      ],
      "metadata": {
        "id": "daa1cfvdKQgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piTjpu82J3Ug"
      },
      "outputs": [],
      "source": [
        "pip install -qU \"langchain[groq]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from secret_keys import groq_key\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "  os.environ[\"GROQ_API_KEY\"] = groq_key\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
      ],
      "metadata": {
        "id": "Ay7NnycDKWNU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify a Pydantic model with a few properties and their expected type in our schema."
      ],
      "metadata": {
        "id": "8hAVuKUYKxpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "id": "QmIXCmgpORtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install langchain-openai"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "kRcJoK3MLLmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "tagging_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "Extract the desired information from the following passage.\n",
        "\n",
        "Only extract the properties mentioned in the 'Classification' function.\n",
        "\n",
        "Passage:\n",
        "{input}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "class Classification(BaseModel):\n",
        "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
        "    aggressiveness: int = Field(\n",
        "        description=\"How aggressive the text is on a scale from 1 to 10\"\n",
        "    )\n",
        "    language: str = Field(description=\"The language the text is written in\")\n",
        "\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\").with_structured_output(\n",
        "    Classification\n",
        ")"
      ],
      "metadata": {
        "id": "sd0qxMwsPQ3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "response = llm.invoke(prompt)\n",
        "\n",
        "response"
      ],
      "metadata": {
        "id": "5PquV2lZPQ5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification(sentiment='positive', aggressiveness=1, language='Spanish')"
      ],
      "metadata": {
        "id": "vPSzcF0UPLFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want dictionary output, we can just call .model_dump()"
      ],
      "metadata": {
        "id": "5EqNDEnQPXEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "response = llm.invoke(prompt)\n",
        "\n",
        "response.model_dump()"
      ],
      "metadata": {
        "id": "M5CEcOAzM0jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'sentiment': 'enojado', 'aggressiveness': 8, 'language': 'es'}"
      ],
      "metadata": {
        "id": "XwXv437QPadh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Finer control**\n",
        "Careful schema definition gives us more control over the model's output.\n",
        "\n",
        "Specifically, we can define:\n",
        "\n",
        "* Possible values for each property\n",
        "* Description to make sure that the model understands the property\n",
        "* Required properties to be returned"
      ],
      "metadata": {
        "id": "xKX7hLD3Pm8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classification(BaseModel):\n",
        "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
        "    aggressiveness: int = Field(\n",
        "        ...,\n",
        "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
        "        enum=[1, 2, 3, 4, 5],\n",
        "    )\n",
        "    language: str = Field(\n",
        "        ..., enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
        "    )"
      ],
      "metadata": {
        "id": "YNRgq5tVPaTP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagging_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "Extract the desired information from the following passage.\n",
        "\n",
        "Only extract the properties mentioned in the 'Classification' function.\n",
        "\n",
        "Passage:\n",
        "{input}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\").with_structured_output(\n",
        "    Classification\n",
        ")"
      ],
      "metadata": {
        "id": "IVmbmkskPaRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "rPpX7OAEPaOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification(sentiment='positive', aggressiveness=1, language='Spanish')"
      ],
      "metadata": {
        "id": "bM7tvo0XQeDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "DHUEDX0zPaHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification(sentiment='enojado', aggressiveness=8, language='es')"
      ],
      "metadata": {
        "id": "lUcxzruVQhCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"Weather is ok here, I can go outside without much more than a coat\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "nfnsPwURPaEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification(sentiment='neutral', aggressiveness=1, language='English')"
      ],
      "metadata": {
        "id": "SJhp62gHQmn6"
      }
    }
  ]
}